---
title: 'Estadistica Aplicada III: Primer Examen Parcial '
author: "Mauricio Vazquez Moran"
date: '2024-10-07'
output:
  pdf_document: default
  html_document: default
---

***Link del repositorio de GitHub: https://github.com/MauricioVazquezM/Multivariate_Statistical_Course_Assignments_Fall2024***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, fig.width=10)

# Libraries
library(MASS)  
library(ggplot2)
library(GGally)
library(mclust)
library(kableExtra)
library(FactoMineR)
library(knitr)
library(caret)
```

<br>

### Pregunta 1: Utilice el WineData de la tarea.

* ***a) Divida los datos en un conjunto de entrenamiento y un conjunto de prueba. Use el conjunto de entrenamiento para construir un clasificador. Justifique su elección de ese clasificador en específico.***
* ***b) Evalúe dicho clasificador. Use al menos dos criterios. Explique sus resultados.***
* ***c) Utilice un gráfico para explicar lo que está haciendo el clasificador propuesto en el primer inciso. Explíquelo que se puede aprender con base a dicho gráfico.***

<br>

Se selecciono un clasificador del tipo Analisis Discriminante Lineal (LDA). Este tiene como objetivo encontrar en el espacio las caracteristicas que maximicen la separacion de clases. Se selecciono este modelo de clasificacion debido a que es un modelo simple que nos brinda alta interpretabilidad en sus resultados y que puede nos brinda un menor riesgo de sobreajuste a comparacion con un QDA, como mas a abajo lo analizaremos. Ademas, al tener un conjunto de datos pequeño en wine.rda, LDA tiene menor probabilidad de sobreajustarlo.

Se separo el conjunto de datos en uno de entrenamiento y uno de prueba para analizar los resultados de este modelo. Lo que se obtuvo fue lo siguiente:

```{r, echo=FALSE}
# Seteando nuestro directorio de trabajo
setwd("~/ITAM/9no Semestre/METODOS MULTIVARIADOS/REPOSITORIO/Multivariate_Statistical_Course_Assignments_Fall2024/EXAM 01")

# Para reproducibilidad
set.seed(123)

# Revisando LDA
load("wine.rda")

# Pasando a dataframe
wine_df <- as.data.frame(wine)

# Pasando a variable categorica
wine_df$classdigit <- as.factor(wine_df$classdigit)

# Dividir los datos en entrenamiento (70%) y prueba (30%)
train_indices <- sample(1:nrow(wine_df), 0.7 * nrow(wine_df))

# Conjunto de entrenamiento
train_data <- wine_df[train_indices, ] 

# Conjunto de prueba
test_data <- wine_df[-train_indices, ] 

# LDA 
lda_model <- lda(classdigit ~ Alcohol + MalicAcid + Ash + AlcAsh + Mg + Phenols + Flav + NonFlavPhenols + Proa + Color + Hue + OD + Proline, 
                 data= train_data)

# Proyectando los datos en el LDA
lda_predictions <- predict(lda_model, test_data)

# Craeando dataframe de las componentes
lda_df <- data.frame(LD1 = lda_predictions$x[, 1], LD2 = lda_predictions$x[, 2], WineType =test_data$class)

# Evaluar el modelo con una matriz de confusión
confusion_matrix_lda <- table(Predicted = lda_predictions$class, Actual = test_data$classdigit)
print(confusion_matrix_lda)

# Calcular precisión
accuracy <- sum(diag(confusion_matrix_lda)) / sum(confusion_matrix_lda)

# Imprimiendo acccuracy
print(paste("Accuracy del modelo LDA:", round(accuracy * 100, 2),"%"))
```

<br>

**Analisis:**

1. La matriz de confusion nos muestra que hubo una observacion de la clase2(Grignolino) que fue incorrectamente clasificada como clase1(Barolo).
2. Por otro lado, la matriz de confusion nos muestra que una observacion de la clase3(Barbera) fue incorrectamente clasificada como clase2(Barolo).
3. La matriz de confusion nos muestra que una observacion de la clase2(Grignolino) fue incorrectamente clasificada como clase3(Barbera).
4. Por lo mencionado arriba, se puede pensar que puede haber cierta superposicion entre las clases 2 y 3, esto debido a los errores capturados por la matriz de confusion.
5. El accuracy del modelo fue del 94.44%. Esto es un muy buen resultado para el modelo de clasificacion LDA. Esta metrica nos indica que el modelo es lo suficientemente robusto para capturar las diferencias entre las 3 clases presentes en el dataset. Si bien es cierto que hay algunas clasificaciones equivocas, en general, el modelo da muy buenos resultados con este conjunto de datos.

<br>

```{r, echo=FALSE}
# Cargando data
setwd("~/ITAM/9no Semestre/METODOS MULTIVARIADOS/REPOSITORIO/Multivariate_Statistical_Course_Assignments_Fall2024/EXAM 01")
load("wine.rda")
wine_df <- as.data.frame(wine)

# Pasando a variable categorica
wine_df$classdigit <- as.factor(wine_df$classdigit)

# Dividir los datos en entrenamiento (70%) y prueba (30%)
train_indices <- sample(1:nrow(wine_df), 0.7 * nrow(wine_df))

# Conjunto de entrenamiento
train_data <- wine_df[train_indices, ] 

# Conjunto de prueba
test_data <- wine_df[-train_indices, ] 

# Ajustar el modelo QDA 
qda_model_wine <- qda(classdigit ~ Alcohol + MalicAcid + Ash + AlcAsh + Mg + 
                 Phenols + Flav + NonFlavPhenols + Proa + Color + Hue + 
                 OD + Proline, data = train_data)

# Realizar predicciones sobre el cojunto de prueba
qda_predictions <- predict(qda_model_wine, test_data)

# Evaluar el modelo con una matriz de confusión
confusion_matrix <- table(Predicted = qda_predictions$class, Actual = test_data$classdigit)
#print(confusion_matrix)

# Calcular precisión
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy del modelo QDA:", round(accuracy * 100, 2),"%"))
```

<br>

Ahora, como se venia mencionando mas arriba, se puede notar que un modelo QDA tiene un accuracy del 100%. Esto si bien es cierto que nos indica un desempeño perfecto en la clasificacion de las clases presentes en wine.rda, nos dice tambien que sobreajusta el conjunto de datos. Dicho en otras palabras, el modelo "memoriza" los datos en lugar de aprender patrones generalizables. Por consecuencia, esto genera una falta de capacidad de generalizar y, por ende, tener un rendimiento malo con datos no vistos por el modelo. En conclusion, esto nos indica que un modelo QDA para un conjunto de datos como este no es el adecuado a usar.

<br>

```{r fig.width=9, fig.height=4, echo=FALSE}
# Ploteando
ggplot(lda_df, aes(x = LD1, y = LD2, color = WineType)) +
  geom_point(size = 3) +
  labs(title = "Scatterplot de las dos primeras Componentes LDA (prediccion)",
       x = "Primera Componente Discriminante (LD1)",
       y = "Segunda Componente Discriminante (LD2)") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

<br>

* Como podemos observar, parecer ser que la primera componente discriminante(LD1) separa mejor Barbera de las otras dos clases, ya que existe cierta distancia en el LD1 entre el grupo de Barbera y los otros dos grupos(Barolo y Grignolino). Esto puede ser un indicativo de que sus caracteristicas son bastantes diferentes a las de Barolo y Grignolino
* Como podemos observar, la segunda componente discriminante brinda una buena separacion entre Barolo y Grignolino, ya que estos se puede observar que estan separadas verticalmente a lo largo del eje LD2. Lo que nos dice que sus caractericticas pueden ser un poco similares y, por ende, obtenemos este resultado. Aunque se debe decir que estan mas cercanas entre si en el espacio de LD1 a comparacion que con Barbera.

**CONCLUSION:**
En general, el modelo de clasificacion propuesto funciona muy bien con un accuracy alto y, por ende, bastante confiable. En comparacion con el modelo QDA, explorado con fines de mostrar el sobreajuste que puede presentar por ser mas complejo, LDA generaliza mejor para este conjunto de datos sin sobreajustarlos y, ante datos no vistos, tendra un mejor desempeño que el modelo QDA. Ademas, dada la dimensionalidad presente en este conjunto de datos, el modelo LDA propuesto es eficiente por su simplicidad y computacionalmente eficiente para lo propuesto.

<br>

### Pregunta 2: los datos de diabetes de la tarea.

* ***a) Aplique al menos 3 métodos de clustering a los datos y explique en que difieren los resultados. ***
* ***b) ¿Cuántos clusters deben reportarse como resultado? Justifique su respuesta.***
* ***c) Explique qué decisiones subjetivas tuvo que tomar al hacer el análisis de clustering. Trate de justificar dichas decisiones.***

Se aplicaron los siguientes tres metodos de clustering jerarquico: single linkage, complete linkage y average linkage. Sabemos que single linkage determina la distancia entre dos grupos como la menor distancia entre un punto de un grupo y un punto del otro. Esto da lugar a clusters mas alargados, ya que los puntos cercanos se agrupan de manera no deseada. Por su parte, complete linkage define la distancia entre dos clusters como la mayor distancia entre un punto de un grupo y un punto del otro. Esto da a lugar a la creacion de clusters mas compactos y puede sacrificar informacion sobre la variabilidad dentro de los grupos. Finalemente, average linakge calcula la distancia entre dos grupos como el promedio de todas las distancias entre los puntos de ambos clusters. Este enfoque permite balancear mejor las distancias, evitar que los clusters se formen unicamente por su forma y puede ser computacionalmente costoso.

```{r, echo=FALSE}
# Cargando data
setwd("~/ITAM/9no Semestre/METODOS MULTIVARIADOS/REPOSITORIO/Multivariate_Statistical_Course_Assignments_Fall2024/EXAM 01")
load("diabetes.rda")
diabetes_df <- as.data.frame(diabetes)

# Quitando la columna class
data<- diabetes_df[, -which(names(diabetes_df) == "class")]

# Computando la distancia euclideana en el dataframe de diabetes
diss_matrix <- dist(data, method="euclidean")
```

```{r fig.width=10, fig.height=5, echo=FALSE}
# Haciendo clustering jerarquico usando el metodo de single-linkage
hc1 <- hclust(diss_matrix, method="single")

# Ploteando 
plot(hc1, cex=0.6, hang=-1,
main = "Dendrograma Single-Linkage",
sub = "Matriz de distancia Euclidiana sobre dataset diabetes", las=2)
```

```{r fig.width=10, fig.height=5, echo=FALSE}
# Haciendo clustering jerarquico usando el metodo de complete-linkage
hc2 <- hclust(diss_matrix, method="complete")

# Ploteando 
plot(hc2, cex=0.6, hang=-1,
main = "Dendrograma Complete-Linkage",
sub = "Matriz de distancia Euclidiana sobre dataset diabetes", las=2)
```

```{r fig.width=10, fig.height=5, echo=FALSE}
# Haciendo clustering jerarquico usando el metodo de average-linkage
hc3 <- hclust(diss_matrix, method="average")

# Ploteando 
plot(hc3, cex=0.6, hang=-1,
main = "Dendrograma Average-Linkage",
sub = "Matriz de distancia Euclidiana sobre dataset diabetes", las=2)
```

<br>

**Analisis:**

1. En primera lugar, se puede observar que el metodo de single-linkage formo clusters mas pequeños y en forma de cadena. Esto sera adecuado en ciertos casos, pero podria generar resultados menos intuitivos. Añadiendo a lo anterior, se notan patrones mas alargados y esto puede ser mas sensible a outliers. Por otro lado, los otros dos metodos permitieron una diferenciacion mas balanceada, con clusters mas equilibrados.
2. En segundo lugar, al observar los dendogramas, notamos que ***con más de 3 clusters*** la variabilidad de los datos ya no se captura de manera tan clara, ya que los clusters se vuelven más pequeños y perdemos información. Por lo tanto, ***con 3 clusters*** obtenemos agrupaciones mas faciles de interpretar. Esto se compagina con lo analizado y comentado en la tarea con este conjunto de datos. Ademas, ***con 3 clusters*** garantizamos que el tamaño de los clusters no sea ni demasiado grande ni demasiado pequeño, evitando la pérdida de información y asegurando que los clusters sean significativos.
3. En tercer lugar, se observan muchos cluster pequeños en alturas bajas en single-linkage. Por su parte, se observa que las uniones ocurridas en complete-linkage son a mayores alturas en el dendograma. Finalmente, en average-linkage esta situacion se sucita a alturas medias. Lo mencionado en este punto hace sentido con lo explicado arriba sobre estos tres metodos de clustering jerarquico.
4. En cuarto lugar, algo particular a resaltar es el balanceo mencionado en el punto uno. El metodo average-linkage brinda un buen balance entre ambos extremos. La estructura es equilibrada y menos compacta que complete-linkage. Esto causa un trade-off entre la compactacion de los clusters y la sensibilidad que pudiera haber por la distancia individual de los puntos.
5. Finalmente, las ***decisiones subjetivas*** tomadas fueron:
    * La decision de utilizar los tres metodos de clustering jerarquico. Se pudo haber optado, en lugar de alguno de estos, por K-medias. Sin embargo, basado en cumplir con el objetivo de la comparacion de los metodos, me parecio mejor utlizar estos tres metodos. 
    * El corte del dendograma. La elección del punto en el que se corta el dendrograma es subjetiva, aunque puede basarse en la intuición para identificar dónde hay una clara separación entre clusters.

